Spiking neural networks require inputs encoded as spike trains. The most common way to do this is to perform a continuous value to frequency transformation using Poisson sources. For most of sensory input in the body, this might be good enough but the retina performs spatio-temporal compression before feeding any information into the cortex.

There are some video-to-spike encoders but have some issues. Real-time encoders require custom hardware and are hard to come by. For off-line encoding, applications are limited to certain type of research, that is no real-time experiments could be performed. Our objective this year was to generate a real-time video-to-spike encoder using of-the-shelf components. 

Of special interest are mobile applications, if we can provide a low-power solution to a silicon retina emulator, we could enable millions of phones, tablets or computers to work as an input to neural computations (QUALCOMM CHIP, SPINNAKER) and keep the traditional camera functionality.

\section{Real-time encoding}
\input{./chapters/rank_ordered_images/real_time_encoding}
%\section{SpiNNaker implementation}
%\input{./chapters/rank_ordered_images/spinnaker_encoding}

\section{Dataset creation}
\input{./chapters/rank_ordered_images/dataset}
\section{Conclusions}
\input{./chapters/rank_ordered_images/conclusions_rank_ordered_images}