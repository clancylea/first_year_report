%Spiking neural networks require inputs encoded as spike trains. 
A common way to encode is to perform a continuous value to frequency transformation using Poisson sources. For most of sensory input in the body, this might be good enough but the retina performs spatio-temporal compression before feeding any information into the cortex.

There are some video-to-spike encoders, but they still have some issues. For instance, most real-time encoders require custom hardware and are hard to come by. As for off-line encoding, applications are limited to certain type of research, that is no real-time experiments could be performed. Our objective this year was to generate a real-time video to spike encoder using of-the-shelf components. 

Of special interest are mobile applications, if we can provide a low-power solution to a silicon retina emulator, we could enable millions of phones, tablets or computers to work as an input to neural computations and while keeping the traditional camera functionality. The first technique we implemented, allows for full image reconstruction from the spike trains; much like what is expected from the retina after a saccade. The second method is, most likely, what the retina does for inter-saccade encoding; this would allow it to keep up with low-power and bandwidth constraints.

\section{Real-time encoding}
\input{./chapters/rank_ordered_images/real_time_encoding}
%\section{SpiNNaker implementation}
%\input{./chapters/rank_ordered_images/spinnaker_encoding}

%\section{Dataset creation}
%\input{./chapters/rank_ordered_images/dataset}
\section{Conclusions}
\input{./chapters/rank_ordered_images/conclusions_rank_ordered_images}