Our approach to solve the SLAM problem is to use spiking neural networks for their efficiency and biological plausibility. The primary external sensor would be visual, either a conventional camera or a dynamic vision sensor. The information from the sensor would then be scanned for landmarks (e.g. a lamp, door, tree, stop sign). To infer the position of the viewer, we will look for inspiration on published work that uses hippocampus models as that organ is known to be a basic component for navigational tasks in animals. A link from visual information to the structure created through the neural network will have to be developed; from this link, a full 3D reconstruction should be available.\\

The milestones of this project are:
\begin{enumerate}
  \item Landmark identification and recognition through spike-based visual input. The initial task would be to develop an on-line learning neural network, the latter would then be modified for identification and recognition tasks.
  \item Tracking of landmarks. Adapt the network from the previous step to be able to provide information of where the landmarks are; this might include some attention modulation for moving objects.
  \item Localization estimation and depth perception. From the information provided by the tracking network (and possibly other sensors), feed another part of a larger network that will estimate the localization of the viewer. A result from this estimation would be the ability to perceive the distance of objects in the scene. 
  \item Mapping and reconstruction. The mapping problem will be solved in parallel to the localization one. For reconstruction a way to connect acquired visual information (i.e. video frames) to the estimated structure in the neural network will be developed and, thus, a full 3D reconstruction 
\end{enumerate}