Environment reconstruction is the problem of converting sensed data into a representation of the scene that provided the information. In particular, 3D reconstruction aims to create a representation similar to what a video game or virtual reality offers. One way of solving this problem is through a technique known as \emph{Simultaneous Localization and Mapping} (SLAM). Though great advances have been achieved with it, most solutions are inefficient and power hungry. Bio-inspired approaches have proven to be efficient solutions to many problems, including SLAM. 

In this document, we present a study of the brain and neuron models. We also review the visual pathway, starting from the retina and ending in the visual cortex. Models of the latter are also analysed. A review of neural networks approaches to the SLAM problem is also presented.

During the first year, the retina and mathematical models that could encode video in real-time were studied and implemented. These will serve as input to our proposed algorithm.

The main contribution of this PhD is to create an efficient, biologically-plausible spiking neural networks SLAM solution. Since this system would combine many vision tasks, a theory of visual perception could also emerge as a result.
