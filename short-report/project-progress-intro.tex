The literature review is about 60\%, though further reading might prove that 
this number might change. 
Converting DVS emu
Converting BASAB model GPU, SPINNAKER, video transfer
Paper on MNIST

%
%Converting frame-based video into spike-trains is a computationally 
%intensive and time consuming task. There are very few equipment that can
%produce spikes from video and they are either in development or too expensive,
%thus every-day users are put behind a virtual wall, leaving them unable to
%experiment with visual input in their simulations or robotics applications. An
%efficient parallel implementation of a simple yet powerful retinal model would
%remove this wall by reducing the time it takes to compute a spike
%representation of a video frame. Furthermore if this is done on
%consumer graphics processing hardware, it will allow almost any user to
%generate their own spike-trains.
%
%In most animals the eye is the organ that captures light so that it can be
%processed in the retina and sent further down the brain as multiple spike
%trains (section \ref{sec-retina}). The retina has been modelled using different
%approaches that go from the extremely detailed (i.e. cell-by-cell)
%\cite{virtual-retina} to the functional
%\cite{basab-model,thorpe-spike-rapid-processing}. We have chosen what we
%believe to be the best model for real-time video processing (section
%\ref{sec-fov-pit}). This model provides a simple and elegant solution to
%encoding, though it suffers from redundancy issues, which are alleviated using
%further processing.
%
%Later in this work we present different strategies to achieve real-time
%encoding into spike trains of video with higher resolution (section
%\ref{sec-parallel}) exploiting the parallelism that comes with image
%processing. To verify that our spike train sets are correct, we test them using
%a reconstruction procedure (section \ref{sec-reconstruction}).

